MyData   <- getSymbols("^SSMI", auto.assign=FALSE, from="1980-01-01", src='yahoo')
head(MyData)
#### important NOTE MyData comes as an xts object
#### an extensible ts object. in short it is a matrix with a time index !
is.xts(MyData)
#dev.off()
#plot(rnorm(50), rnorm(50))
# remove elements that are NA
price = MyData$SSMI.Close
idx   = !is.na(price)
price = price[idx]
autoplot(price)
ret   <- diff(log(price))
ret   <- as.numeric(ret)
N     <- length(ret)
k     <- 30
# first we do the upper tail
ret_sorted <- sort(ret)
logRet <- log(abs(ret_sorted))
plot(logRet[(N-k+1):N], log((k:1)/N),
cex = 1.5,
ylab = "log(i/n)",
xlab = "log(|returns|)",
main = "Upper tail")
YX   <- data.frame( X=logRet[(N-k+1):N], Y=log((k:1)/N))
reg  <- lm(Y~X, data=YX)
summary(reg)
lines(logRet[(N-k+1):N], logRet[(N-k+1):N]*reg$coefficients[2]+reg$coefficients[1],
lwd = 2, col = "red")
# lower tail
ret_sorted <- sort(ret, decreasing = TRUE)
logRet     <- log(abs(ret_sorted))
plot(logRet[(N-k+1):N], log((k:1)/N),
cex = 1.5,
ylab = "log(i/n)",
xlab = "log(|returns|)",
main = "Lower tail")
YX   <- data.frame( X=logRet[(N-k+1):N], Y=log((k:1)/N))
reg  <- lm(Y~X, data=YX)
summary(reg)
lines(logRet[(N-k+1):N],
logRet[(N-k+1):N]*reg$coefficients[2]+reg$coefficients[1],
lwd = 2, col="red")
plt.acf(MyData)
plot.acf(MyData)
acf(MyData)
acf(ret)
acf(ret)
acf(ret)
rm(list=ls()) # clear
library("ggfortify")
library("quantmod")
library("tseries")
library("moments")
### get the SMI data directly from yahoo finance
MyData   <- getSymbols("AMZN", auto.assign=FALSE, from="1990-01-01", src='yahoo')
head(MyData)
#### important NOTE MyData comes as an xts object
#### an extensible ts object. in short it is a matrix with a time index !
is.xts(MyData)
price = MyData$AMZN.Close
idx   = !is.na(price)
price = price[idx]
autoplot(price)
## TASK 1:
# now compute log returns
# delete the "na" (for later purposes)
# plot returns
# now plot returns
ret <- diff(log(price))
idx   = !is.na(ret)
ret = ret[idx]
autoplot(ret) + labs(title="AMZN",
subtitle="Returns",
x ="time") +
theme(panel.grid.minor = element_blank())
##       y =expression(Delta),
## TASK 2
# Compute descriptive statistics on ret:
# use functions from the library 'moments'
# some descriptive statistics on ret:
sumStat <- c(length(ret), min(ret), max(ret), mean(ret), median(ret), sqrt(var(ret)), skewness(ret), kurtosis(ret)  )
print("# elements, min, max, mean, median, std, skew, kurtosis (not excess kurtosis)", quote = FALSE)
cat(sumStat)
# we now compare against normality
# plot a histogram of returns and compare with the a density generated
# from normal variates with same mean and variance:
hist(ret,
100,
prob = TRUE,
col="gray", main = "Histogram", xlab="AMZN returns")
lines( sort(as.numeric(ret)), dnorm(sort(as.numeric(ret)), mean = mean(as.numeric(ret)),
sd = sqrt(var(as.numeric(ret)))),
lwd = 2, col = "red"
)
## TASK 3 do a qqplot on returns
## use qqnorm
qqnorm(ret)
qqline(ret, col=2)
## TASK 4:
# do a Jarque Bera test to test for normality
# use the function jarque.bera.test from the package 'tseries'
jarque.bera.test(ret)
## TASK 5:
# Compute unconditional (daily) volatility
# Compute unconditional monthly, annualized volatility
sd(ret)
sd(ret*sqrt(21)) #monthly
sd(ret*sqrt(252))#yearly
sd(ret)*sqrt(252)
## TASK 6:
# Compute rolling window 30d volatiliy
# Compute eqma  volatiliy
ret2   <- as.numeric(ret^2) ## need to convert to numeric because otherwise loop below fails
N      <- length(ret)
vol30d <- numeric(N)
lambda <-  0.94;
ewma   <- numeric(N)
for (i in 31:N){
vol30d[i] <- sqrt(var(ret[(i-30):i]))
tmp <- ret2[i:1];
ewma[i] <- (1-lambda)*sum((lambda^(0:(i-1)))*tmp)
}
n <- length(ret2)  #gpt version do not trust
vol <- rep(NA,n)
for (i in 30:n) {
vol[i] <- sqrt(30)*sd(ret2[(i-29):i])
}
## compute a for loop here which fills vol30d and ewma:
## ewma has variance unit; convert ewma to vol !
tmp     <- xts(order.by=index(ret))
allVola <- merge(tmp, vol30d=vol30d)
allVola <- merge(allVola, ewma=ewma)
autoplot(allVola[31:N])
## check how different ewma is vis-a-vis vol30d
autoplot(allVola[,1]-allVola[,2])
acf(ret)
acf(log(ret))
acf(ret^2)
acf(abs(ret))
library("fGarch")
install.packages("fGarch")
library("fGarch")
condDist <- "norm"
q <- 1
gfit01 <- garchFit(formula = ~garch(1,0), data = ret, cond.dist = condDist)
summary(gfit01)
# close windows, clear variables
rm(list = ls(all = TRUE))
graphics.off()
# install and load packages
libraries = c("kernlab", "ellipse", "xtable")
lapply(libraries, function(x) if (!(x %in% installed.packages())) {
install.packages(x)
})
lapply(libraries, library, quietly = TRUE, character.only = TRUE)
################################################################################
########################## manipulate subroutine specc #########################
#################### to return eigenvalues and eigenvectors ####################
################################################################################
setGeneric("specc",function(x, ...) standardGeneric("specc"))
setMethod("specc", signature(x = "formula"),
function(x, data = NULL, na.action = na.omit, ...)
{
mt = terms(x, data = data)
if(attr(mt, "response") > 0) stop("response not allowed in formula")
attr(mt, "intercept") = 0
cl                    = match.call()
mf                    = match.call(expand.dots = FALSE)
mf$formula            = mf$x
mf$...                = NULL
mf[[1]]               = as.name("model.frame")
mf                    = eval(mf, parent.frame())
na.act                = attr(mf, "na.action")
x                     = model.matrix(mt, mf)
res                   = specc(x, ...)
cl[[1]] = as.name("specc")
if(!is.null(na.act)) n.action(res) = na.action ;
return(res)
})
setMethod("specc", signature(x = "matrix"),
function(x, centers, kernel = "rbfdot", kpar = "automatic", nystrom.red = FALSE,
nystrom.sample = dim(x)[1]/6, iterations = 200, mod.sample = 0.75,
na.action = na.omit, ...)
{
x    = na.action(x)
rown = rownames(x)
x    = as.matrix(x)
m    = nrow(x)
if (missing(centers)) stop("centers must be a number or a matrix");
if (length(centers) == 1) {
nc =  centers
if (m < centers) stop("more cluster centers than data points.");
}
else nc = dim(centers)[2];
if(is.character(kpar)) {
kpar = match.arg(kpar, c("automatic", "local"))
if(kpar == "automatic") {
if (nystrom.red == TRUE) {
sam = sample(1:m, floor(mod.sample * nystrom.sample))
}else {
sam = sample(1:m, floor(mod.sample * m))
}
sx   = unique(x[sam, ])
ns   = dim(sx)[1]
dota = rowSums(sx * sx) / 2
ktmp = crossprod(t(sx))
for (i in 1:ns) ktmp[i, ] = 2 * (-ktmp[i, ] + dota + rep(dota[i], ns));
## fix numerical prob.
ktmp[ktmp < 0] = 0
ktmp           = sqrt(ktmp)
kmax           = max(ktmp)
kmin           = min(ktmp + diag(rep(Inf,dim(ktmp)[1])))
kmea           = mean(ktmp)
lsmin          = log2(kmin)
lsmax          = log2(kmax)
midmax         = min(c(2 * kmea, kmax))
midmin         = max(c(kmea/2, kmin))
rtmp           = c(seq(midmin, 0.9 * kmea, 0.05 * kmea),
seq(kmea, midmax, 0.08 * kmea))
if ((lsmax - (Re(log2(midmax)) + 0.5)) < 0.5) {
step = (lsmax - (Re(log2(midmax)) + 0.5))
} else {
step = 0.5
}
if (((Re(log2(midmin))-0.5)-lsmin) < 0.5 ) {
stepm = ((Re(log2(midmin)) - 0.5) - lsmin)
} else {
stepm = 0.5
}
tmpsig = c(2^(seq(lsmin, (Re(log2(midmin)) - 0.5), stepm)),
rtmp, 2^(seq(Re(log2(midmax)) + 0.5, lsmax,step)))
diss   = matrix(rep(Inf,length(tmpsig) * nc), ncol = nc)
for (i in 1:length(tmpsig)){
ka       = exp((-(ktmp^2)) / (2 * (tmpsig[i]^2)))
diag(ka) = 0
d        = 1 / sqrt(rowSums(ka))
if(!any(d == Inf) && !any(is.na(d)) && (max(d)[1] - min(d)[1] < 10^4)) {
l         = d * ka %*% diag(d)
xi        = eigen(l, symmetric = TRUE)$vectors[, 1:nc]
yi        = xi / sqrt(rowSums(xi^2))
res       = kmeans(yi, centers, iterations)
diss[i, ] = res$withinss
}
}
ms     = which.min(rowSums(diss))
kernel = rbfdot((tmpsig[ms]^(-2))/2)
## Compute Affinity Matrix
if (nystrom.red == FALSE) km = kernelMatrix(kernel, x);
}
if (kpar=="local") {
if (nystrom.red == TRUE) {
stop ("Local Scaling not supported for nystrom reduction.")
}
s    = rep(0, m)
dota = rowSums(x * x) / 2
dis  = crossprod(t(x))
for (i in 1:m) dis[i, ]= 2 * (-dis[i, ] + dota + rep(dota[i], m));
## fix numerical prob.
dis[dis < 0] = 0
for (i in 1:m) s[i] = median(sort(sqrt(dis[i, ]))[1:5]);
## Compute Affinity Matrix
km     = exp(-dis / s%*%t(s))
kernel = "Localy scaled RBF kernel"
}
} else {
if(!is(kernel, "kernel")) {
if(is(kernel, "function")) kernel = deparse(substitute(kernel));
kernel = do.call(kernel, kpar)
}
if(!is(kernel, "kernel")) stop("kernel must inherit from class `kernel'");
## Compute Affinity Matrix
if (nystrom.red == FALSE) km = kernelMatrix(kernel, x);
}
if (nystrom.red == TRUE){
n      = floor(nystrom.sample)
ind    = sample(1:m, m)
x      = x[ind, ]
tmps   = sort(ind, index.return = TRUE)
reind  = tmps$ix
A      = kernelMatrix(kernel, x[1:n, ])
B      = kernelMatrix(kernel, x[-(1:n), ], x[1:n, ])
d1     = colSums(rbind(A, B))
d2     = rowSums(B) + drop(matrix(colSums(B), 1) %*% .ginv(A) %*% t(B))
dhat   = sqrt(1 / c(d1, d2))
A      = A * (dhat[1:n] %*% t(dhat[1:n]))
B      = B * (dhat[(n + 1):m] %*% t(dhat[1:n]))
Asi    = .sqrtm(.ginv(A))
Q      = A + Asi %*% crossprod(B) %*% Asi
tmpres = svd(Q)
U      = tmpres$u
L      = tmpres$d
V      = rbind(A, B) %*% Asi %*% U %*% .ginv(sqrt(diag(L)))
yi     = matrix(0, m, nc)
# for(i in 2:(nc +1)) yi[,i-1] = V[,i]/V[,1];
## specc
for(i in 1:nc) yi[, i] = V[, i]/sqrt(sum(V[, i]^2));
res = kmeans(yi[reind, ], centers, iterations)
} else {
if(is(kernel)[1] == "rbfkernel") diag(km) = 0;
d   = 1 / sqrt(rowSums(km))
l   = d * km %*% diag(d)
xu  = eigen(l)$values[1:nc]
xi  = eigen(l)$vectors[, 1:nc]
xxu = eigen(l)$values
xxi = eigen(l)$vectors
yi  = xi / sqrt(rowSums(xi^2))
res = kmeans(yi, centers, iterations)
}
ll                 = function(l) colMeans(x[which(res$cluster==l), ])
cent               = matrix(unlist(lapply(1:nc, ll)), ncol = dim(x)[2], byrow = TRUE)
ll                 = function(l) sum((x[which(res$cluster == l),] - cent[l, ])^2);
withss             = unlist(lapply(1:nc, ll))
names(res$cluster) = rown
return(new("specc", .Data = list(data = res$cluster, evalues = xxu, evectors = xxi),
size = res$size, centers = cent, withinss = withss, kernelf = kernel))
})
###########################################################################
############################## main computation ###########################
###########################################################################
set.seed(1)
# define eight points
eight   = cbind(c(-3, -2, -2, -2, 1, 1, 2, 4), c(0, 4, -1, -2, 4, 2, -4, -3))
eight   = eight[c(8, 7, 3, 1, 4, 2, 6, 5), ]
sc      = specc(eight, centers = 2)
centers = attr(sc, "centers") # center coordinates
size    = attr(sc, "size")    # size of clusters
datacl  = sc$data             # clusters
evalues = sc$evalues          # eigenvalues
evectors= sc$evectors         # eigenvectors
# Latex export
xtable(as.matrix(evalues))
xtable(evectors)
# final output
plot(eight, type = "n", xlab = "price conciousness", ylab = "brand loyalty",
xlim = c(-4, 4), main = "8 points")
points(eight, pch = 21, cex = 2.7, bg = "white")
text(eight, as.character(1:8), col = "red3", xlab = "first coordinate",
ylab = "second coordinate", main = "8 points", cex = 1)
lines(ellipse(0.6, centre = centers[2, ], scale = c(1.2, 2)), col = "red3", lwd = 2)
lines(ellipse(0.6, centre = centers[1, ], scale = c(.7, .4)), col = "blue3",lwd = 2)
eight
# clear all variables
rm(list = ls(all = TRUE))
graphics.off()
# Drug data
zi = rbind(c(1, 0, 1, 0, 1, 0, 0, 0, 0, 21), c(1, 0, 1, 0, 0, 1, 0, 0, 0, 32), c(1,
0, 1, 0, 0, 0, 1, 0, 0, 70), c(1, 0, 1, 0, 0, 0, 0, 1, 0, 43), c(1, 0, 1, 0,
0, 0, 0, 0, 1, 19), c(1, 0, 0, 1, 1, 0, 0, 0, 0, 683), c(1, 0, 0, 1, 0, 1, 0,
0, 0, 596), c(1, 0, 0, 1, 0, 0, 1, 0, 0, 705), c(1, 0, 0, 1, 0, 0, 0, 1, 0, 295),
c(1, 0, 0, 1, 0, 0, 0, 0, 1, 99), c(0, 1, 1, 0, 1, 0, 0, 0, 0, 46), c(0, 1, 1,
0, 0, 1, 0, 0, 0, 89), c(0, 1, 1, 0, 0, 0, 1, 0, 0, 169), c(0, 1, 1, 0, 0,
0, 0, 1, 0, 98), c(0, 1, 1, 0, 0, 0, 0, 0, 1, 51), c(0, 1, 0, 1, 1, 0, 0,
0, 0, 738), c(0, 1, 0, 1, 0, 1, 0, 0, 0, 700), c(0, 1, 0, 1, 0, 0, 1, 0,
0, 847), c(0, 1, 0, 1, 0, 0, 0, 1, 0, 336), c(0, 1, 0, 1, 0, 0, 0, 0, 1,
196))
y = zi[, 10]
# Design matrix
I = 2  # sex M - F
J = 2  # drug Yes - No
K = 5  # age category 16-29, 30-44, 45-64, 65-74, 75++
# Mean age per group: for Men and for Women
average = c(c(23.2, 36.5, 54.3, 69.2, 79.5), c(23.2, 36.5, 54.3, 69.2, 79.5))
X   = rbind(c(1, 1), c(1, 1), c(1, 1), c(1, 1), c(1, 1), c(1, -1), c(1, -1), c(1, -1),
c(1, -1), c(1, -1))
X1  = cbind(X, average)  # Xi=design matrix for group i=1,2
n   = dim(X1)
n1  = n[1]
n2  = n[2]
df  = n1 - n2
label = zi[, 3] == 1
n1jk  = y[label]  # nijk is the effective in each cell, i=1,2
label = zi[, 3] == 0
n2jk  = y[label]
b0 = 0 * rep(1, n2)  # current value of beta
# max likelihood in logistic models for 3-way contingency tables
ff = function(b0) {
-sum(n1jk * log(matrix(1, length(n1jk), 1)/(matrix(1, length(n1jk), 1) + exp(-X1 %*%
b0)))) - sum(n2jk * log(matrix(1, dim(matrix(1, length(n1jk), 1)/(matrix(1,
length(n1jk), 1) + exp(-X1 %*% b0)))) - matrix(1, length(n1jk), 1)/(matrix(1,
length(n1jk), 1) + exp(-X1 %*% b0))))
}
(b      = optim(b0, ff)$par)
loglik  = optim(b0, ff)$value
N       = sum(y)
p1      = matrix(1, length(n1jk), 1)/(matrix(1, length(n1jk), 1) + exp(-X1 %*% b))
p2      = matrix(1, length(n2jk), 1)/(matrix(1, length(n2jk), 1) + exp(X1 %*% b))
nfit    = rbind((n1jk + n2jk) * p1, (n1jk + n2jk) * p2)
nobs    = c(n1jk, n2jk)
e       = log(nobs) - log(nfit)
print("degree of freedom")
print(df)
(G2     = 2 * sum(nobs * e))
(pvalG2 = 1 - pchisq(G2, df))
(chi2   = sum(((nobs - nfit)^2)/nfit))
(pvalG2 = 1 - pchisq(G2, df))
print(" ")
print("  observed    fitted")
print("    values    values")
cbind(nobs, nfit)
print(" ")
oddratfit = log(p1/p2)
oddrat    = log(n1jk/n2jk)
plot(X1[1:K, 3], oddratfit[1:K], type = "l", ylim = c(-3.5, -0.5), ylab = "", xlab = "",
lwd = 2)
par(new = TRUE)
plot(X1[(K + 1):(2 * K), 3], oddratfit[(K + 1):(2 * K)], type = "l", ylim = c(-3.5,
-0.5), xlab = "Age category", ylab = "log of odds-ratios", lwd = 2)
points(X1[1:K, 3], oddrat[1:K], pch = "*", cex = 2, col = "red3")
points(X1[(K + 1):(2 * K), 3], oddrat[(K + 1):(2 * K)], cex = 2, col = "blue3")
title(paste("Fit of the log of the odds-ratios "))
# logistic model with curvature term: log(y)~gender + age + age^2
(X2 = cbind(X, average, average * average))
n   = dim(X2)
n1  = n[1]
n2  = n[2]
df2 = n1 - n2
label = zi[, 3] == 1
n1jk  = y[label]
label = zi[, 3] == 0
n2jk  = y[label]
b0 = 0 * rep(1, n2)
f2 = function(b0) {
-sum(n1jk * log(matrix(1, length(n1jk), 1)/(matrix(1, length(n1jk), 1) + exp(-X2 %*%
b0)))) - sum(n2jk * log(matrix(1, dim(matrix(1, length(n1jk), 1)/(matrix(1,
length(n1jk), 1) + exp(-X2 %*% b0)))) - matrix(1, length(n1jk), 1)/(matrix(1,
length(n1jk), 1) + exp(-X2 %*% b0))))
}
(b = optim(b0, f2)$par)
loglik  = optim(b0, f2)$value
N       = sum(y)
p1      = matrix(1, length(n1jk), 1)/(matrix(1, length(n1jk), 1) + exp(-X2 %*% b))
p2      = matrix(1, length(n2jk), 1)/(matrix(1, length(n2jk), 1) + exp(X2 %*% b))
nfit    = rbind((n1jk + n2jk) * p1, (n1jk + n2jk) * p2)
nobs    = c(n1jk, n2jk)
e       = log(nobs) - log(nfit)
print("degree of freedom")
print(df2)
(GG2      = 2 * sum(nobs * e))
(pvalGG2  = 1 - pchisq(GG2, df2))
(chi2     = sum(((nobs - nfit)^2)/nfit))
(pvalG2   = 1 - pchisq(GG2, df2))
print(" ")
print("  observed    fitted")
print("    values    values")
cbind(nobs, nfit)
print(" ")
oddratfit = log(p1/p2)
oddrat    = log(n1jk/n2jk)
dev.new()
plot(X2[1:K, 3], oddratfit[1:K], type = "l", ylim = c(-3.5, -0.5), ylab = "", xlab = "",
lwd = 2)
par(new = TRUE)
plot(X2[(K + 1):(2 * K), 3], oddratfit[(K + 1):(2 * K)], type = "l", ylim = c(-3.5,
-0.5), xlab = "Age category", ylab = "log of odds-ratios", lwd = 2)
points(X2[1:K, 3], oddrat[1:K], pch = "*", cex = 2, col = "red3")
points(X2[(K + 1):(2 * K), 3], oddrat[(K + 1):(2 * K)], cex = 2, col = "blue3")
title(paste("Fit of the log of the odds-ratios "))
# test model one against model two
print("degree of freedom")
print(df - df2)
(overallG2  = G2 - GG2)
(pvaloG2    = 1 - pchisq(overallG2, df - df2))
# clear variables and close windows
rm(list = ls(all = TRUE))
graphics.off()
# install and load packages
libraries = c("glmnet")
lapply(libraries, function(x) if (!(x %in% installed.packages())) {
install.packages(x)
})
lapply(libraries, library, quietly = TRUE, character.only = TRUE)
# load data
data = read.table("carc.dat")
setwd("C:/Users/timda/repo/mva/MVA/QID-2527-MVAlassologit")
# clear variables and close windows
rm(list = ls(all = TRUE))
graphics.off()
# install and load packages
libraries = c("glmnet")
lapply(libraries, function(x) if (!(x %in% installed.packages())) {
install.packages(x)
})
lapply(libraries, library, quietly = TRUE, character.only = TRUE)
# load data
data = read.table("carc.dat")
# recode the response, y = 1 for y > 6000, otherwise y = 0
y   = data[, 2]
n   = length(y)
y   = ifelse(y <= 6000, 0, 1)
x1  = data[, 3]
x2  = data[, 4]
x3  = data[, 5]
x4  = data[, 6]
x5  = data[, 7]
x6  = data[, 8]
x7  = data[, 9]
x8  = data[, 10]
x9  = data[, 11]
x10 = data[, 12]
x11 = data[, 13]
x12 = data[, 14]
x = cbind(x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12)
# lasso
alpa = 1
(lasso.regress = glmnet(x, y, family = "binomial", alpha = alpa, nlambda = 100))
summary(lasso.regress)
# extract coefficients at a single value of lambda
coef(lasso.regress, s = 0.01)
# make predictions
yfit = predict(lasso.regress, newx = x[1:n, ], s = c(0.01))
View(x)
