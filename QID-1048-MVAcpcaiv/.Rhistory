idx   = !is.na(ret)
ret = ret[idx]
autoplot(ret) + labs(title="AMZN",
subtitle="Returns",
x ="time") +
theme(panel.grid.minor = element_blank())
##       y =expression(Delta),
## TASK 2
# Compute descriptive statistics on ret:
# use functions from the library 'moments'
# some descriptive statistics on ret:
sumStat <- c(length(ret), min(ret), max(ret), mean(ret), median(ret), sqrt(var(ret)), skewness(ret), kurtosis(ret)  )
print("# elements, min, max, mean, median, std, skew, kurtosis (not excess kurtosis)", quote = FALSE)
cat(sumStat)
# we now compare against normality
# plot a histogram of returns and compare with the a density generated
# from normal variates with same mean and variance:
hist(ret,
100,
prob = TRUE,
col="gray", main = "Histogram", xlab="AMZN returns")
lines( sort(as.numeric(ret)), dnorm(sort(as.numeric(ret)), mean = mean(as.numeric(ret)),
sd = sqrt(var(as.numeric(ret)))),
lwd = 2, col = "red"
)
## TASK 3 do a qqplot on returns
## use qqnorm
qqnorm(ret)
qqline(ret, col=2)
## TASK 4:
# do a Jarque Bera test to test for normality
# use the function jarque.bera.test from the package 'tseries'
jarque.bera.test(ret)
## TASK 5:
# Compute unconditional (daily) volatility
# Compute unconditional monthly, annualized volatility
sd(ret)
sd(ret*sqrt(21)) #monthly
sd(ret*sqrt(252))#yearly
sd(ret)*sqrt(252)
## TASK 6:
# Compute rolling window 30d volatiliy
# Compute eqma  volatiliy
ret2   <- as.numeric(ret^2) ## need to convert to numeric because otherwise loop below fails
N      <- length(ret)
vol30d <- numeric(N)
lambda <-  0.94;
ewma   <- numeric(N)
for (i in 31:N){
vol30d[i] <- sqrt(var(ret[(i-30):i]))
tmp <- ret2[i:1];
ewma[i] <- (1-lambda)*sum((lambda^(0:(i-1)))*tmp)
}
n <- length(ret2)  #gpt version do not trust
vol <- rep(NA,n)
for (i in 30:n) {
vol[i] <- sqrt(30)*sd(ret2[(i-29):i])
}
## compute a for loop here which fills vol30d and ewma:
## ewma has variance unit; convert ewma to vol !
tmp     <- xts(order.by=index(ret))
allVola <- merge(tmp, vol30d=vol30d)
allVola <- merge(allVola, ewma=ewma)
autoplot(allVola[31:N])
## check how different ewma is vis-a-vis vol30d
autoplot(allVola[,1]-allVola[,2])
acf(ret)
acf(log(ret))
acf(ret^2)
acf(abs(ret))
library("fGarch")
install.packages("fGarch")
library("fGarch")
condDist <- "norm"
q <- 1
gfit01 <- garchFit(formula = ~garch(1,0), data = ret, cond.dist = condDist)
summary(gfit01)
# close windows, clear variables
rm(list = ls(all = TRUE))
graphics.off()
# install and load packages
libraries = c("kernlab", "ellipse", "xtable")
lapply(libraries, function(x) if (!(x %in% installed.packages())) {
install.packages(x)
})
lapply(libraries, library, quietly = TRUE, character.only = TRUE)
################################################################################
########################## manipulate subroutine specc #########################
#################### to return eigenvalues and eigenvectors ####################
################################################################################
setGeneric("specc",function(x, ...) standardGeneric("specc"))
setMethod("specc", signature(x = "formula"),
function(x, data = NULL, na.action = na.omit, ...)
{
mt = terms(x, data = data)
if(attr(mt, "response") > 0) stop("response not allowed in formula")
attr(mt, "intercept") = 0
cl                    = match.call()
mf                    = match.call(expand.dots = FALSE)
mf$formula            = mf$x
mf$...                = NULL
mf[[1]]               = as.name("model.frame")
mf                    = eval(mf, parent.frame())
na.act                = attr(mf, "na.action")
x                     = model.matrix(mt, mf)
res                   = specc(x, ...)
cl[[1]] = as.name("specc")
if(!is.null(na.act)) n.action(res) = na.action ;
return(res)
})
setMethod("specc", signature(x = "matrix"),
function(x, centers, kernel = "rbfdot", kpar = "automatic", nystrom.red = FALSE,
nystrom.sample = dim(x)[1]/6, iterations = 200, mod.sample = 0.75,
na.action = na.omit, ...)
{
x    = na.action(x)
rown = rownames(x)
x    = as.matrix(x)
m    = nrow(x)
if (missing(centers)) stop("centers must be a number or a matrix");
if (length(centers) == 1) {
nc =  centers
if (m < centers) stop("more cluster centers than data points.");
}
else nc = dim(centers)[2];
if(is.character(kpar)) {
kpar = match.arg(kpar, c("automatic", "local"))
if(kpar == "automatic") {
if (nystrom.red == TRUE) {
sam = sample(1:m, floor(mod.sample * nystrom.sample))
}else {
sam = sample(1:m, floor(mod.sample * m))
}
sx   = unique(x[sam, ])
ns   = dim(sx)[1]
dota = rowSums(sx * sx) / 2
ktmp = crossprod(t(sx))
for (i in 1:ns) ktmp[i, ] = 2 * (-ktmp[i, ] + dota + rep(dota[i], ns));
## fix numerical prob.
ktmp[ktmp < 0] = 0
ktmp           = sqrt(ktmp)
kmax           = max(ktmp)
kmin           = min(ktmp + diag(rep(Inf,dim(ktmp)[1])))
kmea           = mean(ktmp)
lsmin          = log2(kmin)
lsmax          = log2(kmax)
midmax         = min(c(2 * kmea, kmax))
midmin         = max(c(kmea/2, kmin))
rtmp           = c(seq(midmin, 0.9 * kmea, 0.05 * kmea),
seq(kmea, midmax, 0.08 * kmea))
if ((lsmax - (Re(log2(midmax)) + 0.5)) < 0.5) {
step = (lsmax - (Re(log2(midmax)) + 0.5))
} else {
step = 0.5
}
if (((Re(log2(midmin))-0.5)-lsmin) < 0.5 ) {
stepm = ((Re(log2(midmin)) - 0.5) - lsmin)
} else {
stepm = 0.5
}
tmpsig = c(2^(seq(lsmin, (Re(log2(midmin)) - 0.5), stepm)),
rtmp, 2^(seq(Re(log2(midmax)) + 0.5, lsmax,step)))
diss   = matrix(rep(Inf,length(tmpsig) * nc), ncol = nc)
for (i in 1:length(tmpsig)){
ka       = exp((-(ktmp^2)) / (2 * (tmpsig[i]^2)))
diag(ka) = 0
d        = 1 / sqrt(rowSums(ka))
if(!any(d == Inf) && !any(is.na(d)) && (max(d)[1] - min(d)[1] < 10^4)) {
l         = d * ka %*% diag(d)
xi        = eigen(l, symmetric = TRUE)$vectors[, 1:nc]
yi        = xi / sqrt(rowSums(xi^2))
res       = kmeans(yi, centers, iterations)
diss[i, ] = res$withinss
}
}
ms     = which.min(rowSums(diss))
kernel = rbfdot((tmpsig[ms]^(-2))/2)
## Compute Affinity Matrix
if (nystrom.red == FALSE) km = kernelMatrix(kernel, x);
}
if (kpar=="local") {
if (nystrom.red == TRUE) {
stop ("Local Scaling not supported for nystrom reduction.")
}
s    = rep(0, m)
dota = rowSums(x * x) / 2
dis  = crossprod(t(x))
for (i in 1:m) dis[i, ]= 2 * (-dis[i, ] + dota + rep(dota[i], m));
## fix numerical prob.
dis[dis < 0] = 0
for (i in 1:m) s[i] = median(sort(sqrt(dis[i, ]))[1:5]);
## Compute Affinity Matrix
km     = exp(-dis / s%*%t(s))
kernel = "Localy scaled RBF kernel"
}
} else {
if(!is(kernel, "kernel")) {
if(is(kernel, "function")) kernel = deparse(substitute(kernel));
kernel = do.call(kernel, kpar)
}
if(!is(kernel, "kernel")) stop("kernel must inherit from class `kernel'");
## Compute Affinity Matrix
if (nystrom.red == FALSE) km = kernelMatrix(kernel, x);
}
if (nystrom.red == TRUE){
n      = floor(nystrom.sample)
ind    = sample(1:m, m)
x      = x[ind, ]
tmps   = sort(ind, index.return = TRUE)
reind  = tmps$ix
A      = kernelMatrix(kernel, x[1:n, ])
B      = kernelMatrix(kernel, x[-(1:n), ], x[1:n, ])
d1     = colSums(rbind(A, B))
d2     = rowSums(B) + drop(matrix(colSums(B), 1) %*% .ginv(A) %*% t(B))
dhat   = sqrt(1 / c(d1, d2))
A      = A * (dhat[1:n] %*% t(dhat[1:n]))
B      = B * (dhat[(n + 1):m] %*% t(dhat[1:n]))
Asi    = .sqrtm(.ginv(A))
Q      = A + Asi %*% crossprod(B) %*% Asi
tmpres = svd(Q)
U      = tmpres$u
L      = tmpres$d
V      = rbind(A, B) %*% Asi %*% U %*% .ginv(sqrt(diag(L)))
yi     = matrix(0, m, nc)
# for(i in 2:(nc +1)) yi[,i-1] = V[,i]/V[,1];
## specc
for(i in 1:nc) yi[, i] = V[, i]/sqrt(sum(V[, i]^2));
res = kmeans(yi[reind, ], centers, iterations)
} else {
if(is(kernel)[1] == "rbfkernel") diag(km) = 0;
d   = 1 / sqrt(rowSums(km))
l   = d * km %*% diag(d)
xu  = eigen(l)$values[1:nc]
xi  = eigen(l)$vectors[, 1:nc]
xxu = eigen(l)$values
xxi = eigen(l)$vectors
yi  = xi / sqrt(rowSums(xi^2))
res = kmeans(yi, centers, iterations)
}
ll                 = function(l) colMeans(x[which(res$cluster==l), ])
cent               = matrix(unlist(lapply(1:nc, ll)), ncol = dim(x)[2], byrow = TRUE)
ll                 = function(l) sum((x[which(res$cluster == l),] - cent[l, ])^2);
withss             = unlist(lapply(1:nc, ll))
names(res$cluster) = rown
return(new("specc", .Data = list(data = res$cluster, evalues = xxu, evectors = xxi),
size = res$size, centers = cent, withinss = withss, kernelf = kernel))
})
###########################################################################
############################## main computation ###########################
###########################################################################
set.seed(1)
# define eight points
eight   = cbind(c(-3, -2, -2, -2, 1, 1, 2, 4), c(0, 4, -1, -2, 4, 2, -4, -3))
eight   = eight[c(8, 7, 3, 1, 4, 2, 6, 5), ]
sc      = specc(eight, centers = 2)
centers = attr(sc, "centers") # center coordinates
size    = attr(sc, "size")    # size of clusters
datacl  = sc$data             # clusters
evalues = sc$evalues          # eigenvalues
evectors= sc$evectors         # eigenvectors
# Latex export
xtable(as.matrix(evalues))
xtable(evectors)
# final output
plot(eight, type = "n", xlab = "price conciousness", ylab = "brand loyalty",
xlim = c(-4, 4), main = "8 points")
points(eight, pch = 21, cex = 2.7, bg = "white")
text(eight, as.character(1:8), col = "red3", xlab = "first coordinate",
ylab = "second coordinate", main = "8 points", cex = 1)
lines(ellipse(0.6, centre = centers[2, ], scale = c(1.2, 2)), col = "red3", lwd = 2)
lines(ellipse(0.6, centre = centers[1, ], scale = c(.7, .4)), col = "blue3",lwd = 2)
eight
# clear all variables
rm(list = ls(all = TRUE))
graphics.off()
# Drug data
zi = rbind(c(1, 0, 1, 0, 1, 0, 0, 0, 0, 21), c(1, 0, 1, 0, 0, 1, 0, 0, 0, 32), c(1,
0, 1, 0, 0, 0, 1, 0, 0, 70), c(1, 0, 1, 0, 0, 0, 0, 1, 0, 43), c(1, 0, 1, 0,
0, 0, 0, 0, 1, 19), c(1, 0, 0, 1, 1, 0, 0, 0, 0, 683), c(1, 0, 0, 1, 0, 1, 0,
0, 0, 596), c(1, 0, 0, 1, 0, 0, 1, 0, 0, 705), c(1, 0, 0, 1, 0, 0, 0, 1, 0, 295),
c(1, 0, 0, 1, 0, 0, 0, 0, 1, 99), c(0, 1, 1, 0, 1, 0, 0, 0, 0, 46), c(0, 1, 1,
0, 0, 1, 0, 0, 0, 89), c(0, 1, 1, 0, 0, 0, 1, 0, 0, 169), c(0, 1, 1, 0, 0,
0, 0, 1, 0, 98), c(0, 1, 1, 0, 0, 0, 0, 0, 1, 51), c(0, 1, 0, 1, 1, 0, 0,
0, 0, 738), c(0, 1, 0, 1, 0, 1, 0, 0, 0, 700), c(0, 1, 0, 1, 0, 0, 1, 0,
0, 847), c(0, 1, 0, 1, 0, 0, 0, 1, 0, 336), c(0, 1, 0, 1, 0, 0, 0, 0, 1,
196))
y = zi[, 10]
# Design matrix
I = 2  # sex M - F
J = 2  # drug Yes - No
K = 5  # age category 16-29, 30-44, 45-64, 65-74, 75++
# Mean age per group: for Men and for Women
average = c(c(23.2, 36.5, 54.3, 69.2, 79.5), c(23.2, 36.5, 54.3, 69.2, 79.5))
X   = rbind(c(1, 1), c(1, 1), c(1, 1), c(1, 1), c(1, 1), c(1, -1), c(1, -1), c(1, -1),
c(1, -1), c(1, -1))
X1  = cbind(X, average)  # Xi=design matrix for group i=1,2
n   = dim(X1)
n1  = n[1]
n2  = n[2]
df  = n1 - n2
label = zi[, 3] == 1
n1jk  = y[label]  # nijk is the effective in each cell, i=1,2
label = zi[, 3] == 0
n2jk  = y[label]
b0 = 0 * rep(1, n2)  # current value of beta
# max likelihood in logistic models for 3-way contingency tables
ff = function(b0) {
-sum(n1jk * log(matrix(1, length(n1jk), 1)/(matrix(1, length(n1jk), 1) + exp(-X1 %*%
b0)))) - sum(n2jk * log(matrix(1, dim(matrix(1, length(n1jk), 1)/(matrix(1,
length(n1jk), 1) + exp(-X1 %*% b0)))) - matrix(1, length(n1jk), 1)/(matrix(1,
length(n1jk), 1) + exp(-X1 %*% b0))))
}
(b      = optim(b0, ff)$par)
loglik  = optim(b0, ff)$value
N       = sum(y)
p1      = matrix(1, length(n1jk), 1)/(matrix(1, length(n1jk), 1) + exp(-X1 %*% b))
p2      = matrix(1, length(n2jk), 1)/(matrix(1, length(n2jk), 1) + exp(X1 %*% b))
nfit    = rbind((n1jk + n2jk) * p1, (n1jk + n2jk) * p2)
nobs    = c(n1jk, n2jk)
e       = log(nobs) - log(nfit)
print("degree of freedom")
print(df)
(G2     = 2 * sum(nobs * e))
(pvalG2 = 1 - pchisq(G2, df))
(chi2   = sum(((nobs - nfit)^2)/nfit))
(pvalG2 = 1 - pchisq(G2, df))
print(" ")
print("  observed    fitted")
print("    values    values")
cbind(nobs, nfit)
print(" ")
oddratfit = log(p1/p2)
oddrat    = log(n1jk/n2jk)
plot(X1[1:K, 3], oddratfit[1:K], type = "l", ylim = c(-3.5, -0.5), ylab = "", xlab = "",
lwd = 2)
par(new = TRUE)
plot(X1[(K + 1):(2 * K), 3], oddratfit[(K + 1):(2 * K)], type = "l", ylim = c(-3.5,
-0.5), xlab = "Age category", ylab = "log of odds-ratios", lwd = 2)
points(X1[1:K, 3], oddrat[1:K], pch = "*", cex = 2, col = "red3")
points(X1[(K + 1):(2 * K), 3], oddrat[(K + 1):(2 * K)], cex = 2, col = "blue3")
title(paste("Fit of the log of the odds-ratios "))
# logistic model with curvature term: log(y)~gender + age + age^2
(X2 = cbind(X, average, average * average))
n   = dim(X2)
n1  = n[1]
n2  = n[2]
df2 = n1 - n2
label = zi[, 3] == 1
n1jk  = y[label]
label = zi[, 3] == 0
n2jk  = y[label]
b0 = 0 * rep(1, n2)
f2 = function(b0) {
-sum(n1jk * log(matrix(1, length(n1jk), 1)/(matrix(1, length(n1jk), 1) + exp(-X2 %*%
b0)))) - sum(n2jk * log(matrix(1, dim(matrix(1, length(n1jk), 1)/(matrix(1,
length(n1jk), 1) + exp(-X2 %*% b0)))) - matrix(1, length(n1jk), 1)/(matrix(1,
length(n1jk), 1) + exp(-X2 %*% b0))))
}
(b = optim(b0, f2)$par)
loglik  = optim(b0, f2)$value
N       = sum(y)
p1      = matrix(1, length(n1jk), 1)/(matrix(1, length(n1jk), 1) + exp(-X2 %*% b))
p2      = matrix(1, length(n2jk), 1)/(matrix(1, length(n2jk), 1) + exp(X2 %*% b))
nfit    = rbind((n1jk + n2jk) * p1, (n1jk + n2jk) * p2)
nobs    = c(n1jk, n2jk)
e       = log(nobs) - log(nfit)
print("degree of freedom")
print(df2)
(GG2      = 2 * sum(nobs * e))
(pvalGG2  = 1 - pchisq(GG2, df2))
(chi2     = sum(((nobs - nfit)^2)/nfit))
(pvalG2   = 1 - pchisq(GG2, df2))
print(" ")
print("  observed    fitted")
print("    values    values")
cbind(nobs, nfit)
print(" ")
oddratfit = log(p1/p2)
oddrat    = log(n1jk/n2jk)
dev.new()
plot(X2[1:K, 3], oddratfit[1:K], type = "l", ylim = c(-3.5, -0.5), ylab = "", xlab = "",
lwd = 2)
par(new = TRUE)
plot(X2[(K + 1):(2 * K), 3], oddratfit[(K + 1):(2 * K)], type = "l", ylim = c(-3.5,
-0.5), xlab = "Age category", ylab = "log of odds-ratios", lwd = 2)
points(X2[1:K, 3], oddrat[1:K], pch = "*", cex = 2, col = "red3")
points(X2[(K + 1):(2 * K), 3], oddrat[(K + 1):(2 * K)], cex = 2, col = "blue3")
title(paste("Fit of the log of the odds-ratios "))
# test model one against model two
print("degree of freedom")
print(df - df2)
(overallG2  = G2 - GG2)
(pvaloG2    = 1 - pchisq(overallG2, df - df2))
setwd("C:/Users/timda/repo/mva/MVA/QID-1048-MVAcpcaiv")
# load data
data1 = read.table("XFGvolsurf01.dat")  # 1 month maturity data
data2 = read.table("XFGvolsurf02.dat")  # 2 months maturity data
data3 = read.table("XFGvolsurf03.dat")  # 3 months maturity data
S1 = cov(data1) * 1e+05  # Sample covariance*10^5 of 1 month maturity data
S2 = cov(data2) * 1e+05  # Sample covariance*10^5 of 2 months maturity data
S3 = cov(data3) * 1e+05  # Sample covariance*10^5 of 3 months maturity data
S = rbind(S1, S2, S3)    # Combine data by rows
A = array(t(S), c(ncol(S1), ncol(S2), 3))  # Create a 3d array
n = c(253, 253, 253)     # Number of trading days in 1999
N = n - 1
preB    = 1e-10          # Precision for maximum deviation of an element of matrix B
maxit   = 15             # Maximal number of iteration
preQ    = 1e-10          # Precision for maximum deviation of an element of matrix Q
maxiter = 10             # Maximal number of iteration
p       = dim(A)[1]      # Covariances are pxp
k       = dim(A)[3]      # Number of groups
B       = diag(p)        # Initial value for B, the unit matrix
f = 0
repeat {
f = f + 1
Bold = B
j = 1
while (j <= p) {
m = 1
while (m < j) {
Bmj = cbind(B[, m], B[, j])
(T = array(0, c(2, 2, k)))
T[, , 1] = t(Bmj) %*% A[, , 1] %*% Bmj
T[, , 2] = t(Bmj) %*% A[, , 2] %*% Bmj
T[, , 3] = t(Bmj) %*% A[, , 3] %*% Bmj
Q = cbind(c(1, 0), c(0, 1))  # orthogonal matrix to start with
g = 0
repeat {
g = g + 1
Qold = Q
Delta1 = array(Q, c(2, 2, k)) * T * (array(Q, c(2, 2, k)))
diag(Delta1[, , 1])
Delta = array(c(diag(Delta1[, , 1])), c(2, 1, 3))
Delta[, , 1] = c(diag(Delta1[, , 1]))
Delta[, , 2] = c(diag(Delta1[, , 2]))
Delta[, , 3] = c(diag(Delta1[, , 3]))
a = t(Delta[, , 1])
b = t(Delta[, , 2])
c = t(Delta[, , 3])
abc = matrix(cbind(a, b, c), 2, 3)
abcd = t(abc)
d = N * (abcd[, 1] - abcd[, 2])/(abcd[, 1] * abcd[, 2])
Tsum1 = array(0, c(2, 2, k))
Tsum1[, , 1] = d[1] * T[, , 1]
Tsum1[, , 2] = d[2] * T[, , 2]
Tsum1[, , 3] = d[3] * T[, , 3]
f = sum(Tsum1[, 1, ][1, ])
g = sum(Tsum1[, 1, ][2, ])
h = sum(Tsum1[, 2, ][1, ])
y = sum(Tsum1[, 2, ][2, ])
Tsum = matrix(rbind(f, g, h, y), 2, 2)
e = eigen(Tsum)
Q = e$vectors  # find eigenvectors of Tsum
maxim = max(abs(Q - Qold))
if ((maxim < preQ) | (g > maxiter))
break
}
J = diag(p)
J[m, m] = Q[1, 1]
J[m, j] = Q[1, 2]
J[j, m] = Q[2, 1]
J[j, j] = Q[2, 2]
B = B %*% J
m = m + 1
print(m)
}
j = j + 1
}
maximum = max(abs(B - Bold))
if ((maximum < preB) | (f > maxit))
break
}
lambda1 = array(t(B), c(p, p, k)) * A * (array(B, c(p, p, k)))
lambda  = array(c(diag(lambda1[, , 1])), c(p, 1, 3))
lambda[, , 1] = c(diag(lambda1[, , 1]))
lambda[, , 2] = c(diag(lambda1[, , 2]))
lambda[, , 3] = c(diag(lambda1[, , 3]))
a1b1c1 = matrix(cbind(t(lambda[, , 1]), t(lambda[, , 2]), t(lambda[, , 3])), p, k)
# Sort eigenvectors according to size of its corresponding eigenvalues
u   = rbind(t(a1b1c1), B)
us  = t(u)
us  = us[order(us[, 1]), ]
uss = us[p:1, ]
B   = t(uss[, (k + 1):(k + p)])
BB  = t(B[, 1:k])
# plot
plot(BB[1, ], type = "l", lwd = 4, ylim = c(-1, 1), xlab = "moneyness", ylab = "loading",
main = "PCP for CPCA, 3 eigenvectors")
lines(BB[2, ], type = "l", lwd = 3)
lines(BB[3, ], type = "l", lwd = 2)
# estimated population covariances
V          = array(0, c(p, p, k))
V[, , 1]   = uss[, 1] * diag(p)
V[, , 2]   = uss[, 2] * diag(p)
V[, , 3]   = uss[, 3] * diag(p)
psi = array(0, c(p, p, k))
psi[, , 1] = B %*% V[, , 1] %*% t(B)
psi[, , 2] = B %*% V[, , 2] %*% t(B)
psi[, , 3] = B %*% V[, , 3] %*% t(B)
# Test statistic
de   = c(det(psi[, , 1]), det(psi[, , 2]), det(psi[, , 3]))
det  = c(det(A[, , 1]), det(A[, , 2]), det(A[, , 3]))
test = 2 * log(t(n - 1) %*% (de/det))
# P-value
df = 1/2 * (k - 1) * p * (p - 1)
t  = 1 - pchisq(test, df)
diag(6)
pchisq(0.9, 5)
t
t
test
1 - pchisq(31.836, 30)
